<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.12: http://docutils.sourceforge.net/" />
<title></title>
<style type="text/css">

/*
:Author: David Goodger (goodger@python.org)
:Id: lab4.html,v 1.8 2019/10/03 08:45:53 sgwater Exp
:Copyright: This stylesheet has been placed in the public domain.

Default cascading style sheet for the HTML output of Docutils.

See http://docutils.sf.net/docs/howto/html-stylesheets.html for how to
customize this style sheet.
*/

/* used to remove borders from tables and images */
.borderless, table.borderless td, table.borderless th {
  border: 0 }

table.borderless td, table.borderless th {
  /* Override padding for "table.docutils td" with "! important".
     The right padding separates the table cells. */
  padding: 0 0.5em 0 0 ! important }

.first {
  /* Override more specific margin styles with "! important". */
  margin-top: 0 ! important }

.last, .with-subtitle {
  margin-bottom: 0 ! important }

.hidden {
  display: none }

a.toc-backref {
  text-decoration: none ;
  color: black }

blockquote.epigraph {
  margin: 2em 5em ; }

dl.docutils dd {
  margin-bottom: 0.5em }

object[type="image/svg+xml"], object[type="application/x-shockwave-flash"] {
  overflow: hidden;
}

/* Uncomment (and remove this text!) to get bold-faced definition list terms
dl.docutils dt {
  font-weight: bold }
*/

div.abstract {
  margin: 2em 5em }

div.abstract p.topic-title {
  font-weight: bold ;
  text-align: center }

div.admonition, div.attention, div.caution, div.danger, div.error,
div.hint, div.important, div.note, div.tip, div.warning {
  margin: 2em ;
  border: medium outset ;
  padding: 1em }

div.admonition p.admonition-title, div.hint p.admonition-title,
div.important p.admonition-title, div.note p.admonition-title,
div.tip p.admonition-title {
  font-weight: bold ;
  font-family: sans-serif }

div.attention p.admonition-title, div.caution p.admonition-title,
div.danger p.admonition-title, div.error p.admonition-title,
div.warning p.admonition-title, .code .error {
  color: red ;
  font-weight: bold ;
  font-family: sans-serif }

/* Uncomment (and remove this text!) to get reduced vertical space in
   compound paragraphs.
div.compound .compound-first, div.compound .compound-middle {
  margin-bottom: 0.5em }

div.compound .compound-last, div.compound .compound-middle {
  margin-top: 0.5em }
*/

div.dedication {
  margin: 2em 5em ;
  text-align: center ;
  font-style: italic }

div.dedication p.topic-title {
  font-weight: bold ;
  font-style: normal }

div.figure {
  margin-left: 2em ;
  margin-right: 2em }

div.footer, div.header {
  clear: both;
  font-size: smaller }

div.line-block {
  display: block ;
  margin-top: 1em ;
  margin-bottom: 1em }

div.line-block div.line-block {
  margin-top: 0 ;
  margin-bottom: 0 ;
  margin-left: 1.5em }

div.sidebar {
  margin: 0 0 0.5em 1em ;
  border: medium outset ;
  padding: 1em ;
  background-color: #ffffee ;
  width: 40% ;
  float: right ;
  clear: right }

div.sidebar p.rubric {
  font-family: sans-serif ;
  font-size: medium }

div.system-messages {
  margin: 5em }

div.system-messages h1 {
  color: red }

div.system-message {
  border: medium outset ;
  padding: 1em }

div.system-message p.system-message-title {
  color: red ;
  font-weight: bold }

div.topic {
  margin: 2em }

h1.section-subtitle, h2.section-subtitle, h3.section-subtitle,
h4.section-subtitle, h5.section-subtitle, h6.section-subtitle {
  margin-top: 0.4em }

h1.title {
  text-align: center }

h2.subtitle {
  text-align: center }

hr.docutils {
  width: 75% }

img.align-left, .figure.align-left, object.align-left {
  clear: left ;
  float: left ;
  margin-right: 1em }

img.align-right, .figure.align-right, object.align-right {
  clear: right ;
  float: right ;
  margin-left: 1em }

img.align-center, .figure.align-center, object.align-center {
  display: block;
  margin-left: auto;
  margin-right: auto;
}

.align-left {
  text-align: left }

.align-center {
  clear: both ;
  text-align: center }

.align-right {
  text-align: right }

/* reset inner alignment in figures */
div.align-right {
  text-align: inherit }

/* div.align-center * { */
/*   text-align: left } */

ol.simple, ul.simple {
  margin-bottom: 1em }

ol.arabic {
  list-style: decimal }

ol.loweralpha {
  list-style: lower-alpha }

ol.upperalpha {
  list-style: upper-alpha }

ol.lowerroman {
  list-style: lower-roman }

ol.upperroman {
  list-style: upper-roman }

p.attribution {
  text-align: right ;
  margin-left: 50% }

p.caption {
  font-style: italic }

p.credits {
  font-style: italic ;
  font-size: smaller }

p.label {
  white-space: nowrap }

p.rubric {
  font-weight: bold ;
  font-size: larger ;
  color: maroon ;
  text-align: center }

p.sidebar-title {
  font-family: sans-serif ;
  font-weight: bold ;
  font-size: larger }

p.sidebar-subtitle {
  font-family: sans-serif ;
  font-weight: bold }

p.topic-title {
  font-weight: bold }

pre.address {
  margin-bottom: 0 ;
  margin-top: 0 ;
  font: inherit }

pre.literal-block, pre.doctest-block, pre.math, pre.code {
  margin-left: 2em ;
  margin-right: 2em }

pre.code .ln { color: grey; } /* line numbers */
pre.code, code { background-color: #eeeeee }
pre.code .comment, code .comment { color: #5C6576 }
pre.code .keyword, code .keyword { color: #3B0D06; font-weight: bold }
pre.code .literal.string, code .literal.string { color: #0C5404 }
pre.code .name.builtin, code .name.builtin { color: #352B84 }
pre.code .deleted, code .deleted { background-color: #DEB0A1}
pre.code .inserted, code .inserted { background-color: #A3D289}

span.classifier {
  font-family: sans-serif ;
  font-style: oblique }

span.classifier-delimiter {
  font-family: sans-serif ;
  font-weight: bold }

span.interpreted {
  font-family: sans-serif }

span.option {
  white-space: nowrap }

span.pre {
  white-space: pre }

span.problematic {
  color: red }

span.section-subtitle {
  /* font-size relative to parent (h1..h6 element) */
  font-size: 80% }

table.citation {
  border-left: solid 1px gray;
  margin-left: 1px }

table.docinfo {
  margin: 2em 4em }

table.docutils {
  margin-top: 0.5em ;
  margin-bottom: 0.5em }

table.footnote {
  border-left: solid 1px black;
  margin-left: 1px }

table.docutils td, table.docutils th,
table.docinfo td, table.docinfo th {
  padding-left: 0.5em ;
  padding-right: 0.5em ;
  vertical-align: top }

table.docutils th.field-name, table.docinfo th.docinfo-name {
  font-weight: bold ;
  text-align: left ;
  white-space: nowrap ;
  padding-left: 0 }

/* "booktabs" style (no vertical lines) */
table.docutils.booktabs {
  border: 0px;
  border-top: 2px solid;
  border-bottom: 2px solid;
  border-collapse: collapse;
}
table.docutils.booktabs * {
  border: 0px;
}
table.docutils.booktabs th {
  border-bottom: thin solid;
  text-align: left;
}

h1 tt.docutils, h2 tt.docutils, h3 tt.docutils,
h4 tt.docutils, h5 tt.docutils, h6 tt.docutils {
  font-size: 100% }

ul.auto-toc {
  list-style-type: none }

</style>
</head>
<body>
<div class="document">


<div class="section" id="lab-4-pos-tagging">
<h1>Lab 4: POS Tagging</h1>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Authors:</th><td class="field-body">Henry Thompson, Bharat Ram Ambati, Ida Szubert</td>
</tr>
<tr class="field"><th class="field-name">Date:</th><td class="field-body">2014-10-01, 2017-10-09, 2018-10-11</td>
</tr>
<tr class="field"><th class="field-name">Copyright:</th><td class="field-body">This work is licensed under a <a class="reference external" href="http://creativecommons.org/licenses/by-nc/4.0/.">Creative Commons Attribution-NonCommercial 4.0 International License</a>: You may re-use, redistribute, or modify this work for non-commercial purposes provided you retain attribution to any previous author(s).</td>
</tr>
</tbody>
</table>
<p>You can use the <a class="reference external" href="http://www.inf.ed.ac.uk/teaching/courses/anlp/labs/lab4.html">online version</a>
of this lab if you want to easily access the links or copy and paste commands.</p>
</div>
<div class="section" id="goals-and-motivation-of-this-lab">
<h1>Goals and motivation of this lab</h1>
<p>Part-of-Speech (POS) tagging is the task of identifying the
part-of-speech for each word in a given text.  'Tagging', because the
symbol used to label part-of-speech is called a 'tag'.  Tagging is one
of the basic steps in developing Natural Language Processing (NLP)
tools such as parsers, question answerers etc. In this lab, we will
explore POS tagging and build a simple POS tagger.</p>
<p>As before, we have written most of the code for the lab already and
included a lot of explanatory comments, but we will ask you to add a
few things here and there. For students with more programming
background, the 'Going Further' section will give you a chance to
explore some more advanced topics.</p>
</div>
<div class="section" id="preliminaries">
<h1>Preliminaries</h1>
<p>As usual, create a directory for this lab inside your <tt class="docutils literal">labs</tt>
directory:</p>
<pre class="literal-block">
cd ~/anlp/labs
mkdir lab4
cd lab4
</pre>
<p>Download the file <a class="reference external" href="http://www.inf.ed.ac.uk/teaching/courses/anlp/labs/lab4.py">lab4.py</a> into your <tt class="docutils literal">lab4</tt> directory and open it for editing using Spyder or your favorite editor.</p>
</div>
<div class="section" id="nltk">
<h1>NLTK</h1>
<p>In this lab, we use <a class="reference external" href="http://www.nltk.org/">NLTK</a> library. NLTK ( Natural Language Toolkit )
is a popular library for language processing tasks which is developed
in python. It has several useful packages for NLP tasks like
tokenization, tagging, parsing etc. In this lab, we use very basic
functions like loading the data, reading sentences. You will be asked
to write few lines of code in a fuction to answer some questions in
this lab. Some of these functions are already implemented in NLTK. You
can explore those options for questions in 'Going Further' section as
Home work.</p>
</div>
<div class="section" id="pos-tagset">
<h1>POS Tagset</h1>
<p>POS tagset is the set of Part-of-Speech tags used for annotating a
particular corpus. <a class="reference external" href="http://www.americannationalcorpus.org/oanc/penn.html">Penn Tagset</a> is one such tagset which is widely
used in NLP tasks. Have a look at the tagset. Based on your intution
guess the most and least frequent tags in a data. What is the
difference between the tags DT and PDT? Can you distinguish singular
and plural nouns using this tagset? If so, how? How many different
tags are available for main verbs and what are they?</p>
</div>
<div class="section" id="running-the-code">
<h1>Running the code</h1>
<p>You can run this week's lab as follows:</p>
<pre class="literal-block">
%run lab4.py
</pre>
<p>It should print the first tagged sentence, and first word, tag
tuple. It also should print basic statistics about the data like total
number of sentences and the average sentence length (number of words
per sentence).</p>
<p>For subsequent runs, you can skip the printing by doing:</p>
<pre class="literal-block">
%run lab4.py -q
</pre>
<p>or setting the command line options to <tt class="docutils literal"><span class="pre">-q</span></tt> in Spyder (for instructions see lab 2 handout).
For this lab, we consider a small part of the Penn Treebank POS
annotated data. This data consists of around 3900 sentences, where
each word is annotated with its POS tag using the Penn POS tagset. We
use nltk libraries to load this data and extract tagged sentences. We
first import the <tt class="docutils literal">dependency_treebank</tt> from nltk.corpus package
using the command <tt class="docutils literal">from nltk.corpus import dependency_treebank</tt>. We
can extract the tagged sentences using the following command:</p>
<pre class="literal-block">
tsents = dependency_treebank.tagged_sents()
</pre>
<p><tt class="docutils literal">tsents</tt> contains a list of <tt class="docutils literal">tagged sentences</tt>. A <tt class="docutils literal">tagged
sentence</tt> is a list of pairs, where each pair consists of a word and
its POS tag. A pair is just a Tuple with two members, and a <tt class="docutils literal">Tuple</tt>
is a data structure that is similar to a list, except that you can't
change its length or its contents.  The Python <a class="reference external" href="https://docs.python.org/release/1.5.1p1/tut/tuples.html">Tuple</a> documentation
provides a useful summary introduction to tuples.</p>
<p>Once you've loaded lab4.py, <tt class="docutils literal">tsents[0]</tt> contains the
first tagged sentence. <tt class="docutils literal"><span class="pre">tsents[0][0]</span></tt> gives the first tuple in the
first sentence which is a word, tag pair, and <tt class="docutils literal"><span class="pre">tsents[0][0][0]</span></tt>
gives you the word from that pair, <tt class="docutils literal"><span class="pre">tsents[0][0][1]</span></tt> its tag.</p>
</div>
<div class="section" id="distribution-of-sentence-lengths">
<h1>Distribution of sentence lengths</h1>
<p>Construct a frequency distribution of sentence length by completing the
code in the <tt class="docutils literal">sent_length_distribution</tt> function, which returns a
dictionary with sentence lengths as keys and the number of sentences with a
particular length as values.  Use the <tt class="docutils literal">plot_histogram</tt> function to
plot this distribution, sorted in order of sentence length.  Remember
to expand the plot window so you can see what's going on, and to close
it when you want to get back to ipython.</p>
<p>(Don't forget to do:</p>
<pre class="literal-block">
%run lab4.py
</pre>
<p>after you've done some edits, in order to get your new function
definitions.)</p>
<p>What are the minimum and maximum sentence lengths that you see?  What
kind of distribution is this?</p>
</div>
<div class="section" id="distribution-of-tags">
<h1>Distribution of tags</h1>
<p>Construct a frequency distribution of POS tags by completing the code
in the <tt class="docutils literal">tag_distribution</tt> function, which returns a dictionary with
POS tags as keys and the number of word tokens with that tag as
values. How many distinct tags are present in the data? List the tags
in the descreasing order of frequency. What are the 5 most frequent
and least frequent tags in this data. How does this compare with your
intution in the previous section? Using <tt class="docutils literal">plot_histogram</tt>, plot
a histogram of the tag distribution with tags on the x-axis and their
counts on the y-axis, ordered by descending frequency.</p>
<p>In the previous labs, you have learnt how to sort dictionary <em>keys</em> based
on their <em>values</em> (eg: <tt class="docutils literal">sorted(mydict, key=mydict.get)</tt>). You can
adapt this approach to return a sorted list of keys <em>and</em> values,
which is what you need for the above plot. For example, the
following command returns list of dictionary entries sorted by values:</p>
<pre class="literal-block">
sorted(mydict.items(), key=lambda x: x[1])
</pre>
<p>Providing <tt class="docutils literal">reverse=True</tt> as the third argument gives the result in
reverse order.  <tt class="docutils literal">help(sorted)</tt> is your friend.</p>
<p>What kind of distribution do you see in the plot?</p>
</div>
<div class="section" id="distribution-of-tags-and-words">
<h1>Distribution of tags and words</h1>
<p>Construct a conditional frequency distribution (CFD) by completing the code in the
<tt class="docutils literal">word_tag_distribution</tt> function.  A CFD is a dictionary whose values are
themselves distributions, keyed by context or condition.  In our case
we want words as conditions == keys, with values a frequency
distribution of tags <em>for that word</em>.</p>
<p>For example, for the word <em>book</em>, the value of your CFD should be a frequency
distribution of the POS tags that occur with <em>book</em>.</p>
<p>How many entries are there in your big CFD?  Given what each entry corresponds
to, what does this number tell us about the corpus?</p>
<p>What is the number of tags and the most frequent tag for
the word <em>the</em>?  Does what you see make you wonder about the tagging
process, and how it was checked?</p>
<p>What about <em>in</em>, <em>book</em>, <em>eat</em>?  Which word out of the whole corpus has
the greatest number of distinct tags?  (Hint: fill in the blank:</p>
<pre class="literal-block">
pprint(sorted(word_tag_dist.items(),key=lambda (w,fd):________,reverse=True)[:10])

(``pprint`` (think *pretty print*) is often useful if you have lots
of nested dictionaries, lists and tuples to look at. . .)
</pre>
<p>What are the tags which occur with the tag-ambiguous word and what
parts of speech do they represent?</p>
</div>
<div class="section" id="nltk-frequency-distribution-functions">
<h1>NLTK Frequency Distribution functions</h1>
<p>NLTK has two in-built functions FreqDist() and ConditionalFreqDist()
which compute frequency distribution and conditional frequency
distribution respectively. These functions are similar to the ones we
just implemented. They have several additional useful features, such
as <tt class="docutils literal">tabulate()</tt>, which prints a frequency distribution in tabular
form and <tt class="docutils literal">plot()</tt>, which plots it in inverse frequency order.</p>
<p>For these functions, we need a single long list of word and tag
pairs. <tt class="docutils literal">dependency_treebank.tagged_words()</tt> can be used to
get such a list from our corpus:</p>
<pre class="literal-block">
wtPairs = dependency_treebank.tagged_words()
</pre>
<p>Using <tt class="docutils literal">FreqDist</tt> and a simple comprehension, we can then get a
frequency distribution for just the words in our corpus:</p>
<pre class="literal-block">
wfd=FreqDist(w for (w,t) in wtPairs)
wfd
wfd.plot(50)
</pre>
<p>And finally using <tt class="docutils literal">ConditionalFreqDist()</tt>, we can compute the conditional
frequency distribution of word and tag pairs for our corpus like this:</p>
<pre class="literal-block">
cfd = ConditionalFreqDist(wtPairs)
the_fd = cfd['the']
the_fd
len(the_fd)
the_fd.tabulate()
</pre>
<p><tt class="docutils literal"><span class="pre">cfd['the']</span></tt> gives the frequency distribution of tags for the word
<em>the</em>. <tt class="docutils literal">fd.tabulate()</tt> prints this distribution in tabular
form. Compare this with the conditional frequency distribution
computed in the previous section, for the word <em>the</em>. Both should
give same results.</p>
</div>
<div class="section" id="unigram-tagger">
<h1>Unigram Tagger</h1>
<p>We shall now build a simple POS tagger called a <em>unigram</em> tagger using
the function <tt class="docutils literal">unigram_tagger</tt>. This fuction takes three
arguments. The first one is a conditional frequency distribution,
which can be generated using the nltk functions described above. The
second argument is the most frequent POS tag. The third argument is a
sentence that needs to be tagged. The goal of this function is to tag
the sentence using probabilities from the CFD and most frequent POS
tag. In order to make it work, you must complete its helper function,
called <tt class="docutils literal">ut1</tt>, to process a single word. If the word is seen (present
in the CFD), it should assign the most frequent tag for that word. For
unseen words (not present in the CFD), it should assign the overall
most frequent POS tag, as passed in as the 3rd argument.</p>
<p>Why is this called a Unigram tagger?  How does it differ from an HMM
tagger?</p>
<p>Run this simple tagger and tag the sentences a) &quot;book a flight to
London&quot; and b) &quot;I bought a new book&quot;. Look at the POS tags. Are there
any errors in the POS tags? If so, what could be the reason for them?</p>
</div>
<div class="section" id="going-further">
<h1>Going further</h1>
<p>1. Run the simple tagger developed on the sentence &quot;I bought two new
books.&quot;  What error do you see, and what improvement can you think of
that can handle it?</p>
<p>2. Do you think the Penn tagset will work well for social media text
such as twitter data which contains non-standard English text?</p>
<p>3. NLTK has libraries to train different taggers. Using these
libraries, build unigram and Hidden Markov Model taggers and evaluate
them. First, split the data into two parts(90%, 10%). Consider first
90% of the data as training data and the remaining 10% of the data as
testing data. Build taggers using the training data. Then run the
taggers on the test data and evaluate the performance of the tagger</p>
<p><tt class="docutils literal">help(nltk.tag.hmm.HiddenMarkovModelTagger)</tt> and
<tt class="docutils literal">help(nltk.UnigramTagger)</tt> are your friends.  Note particularly the
<tt class="docutils literal">evaluate</tt> function for evaluating the tagging of a collection of
test sentences.</p>
</div>
</div>
</body>
</html>
